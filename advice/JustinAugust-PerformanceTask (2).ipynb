{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summit Schools Manager of Data Performance Task\n",
    "## Prepared by Justin August"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define today's date for filename usage pater on.\n",
    "\n",
    "TODAY = date.today().strftime('%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A dictionary to hold site metadata such as shortname and site name each site.\n",
    "\n",
    "_This would need to be expanded and customized for each data source as schools were added_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AL: maybe small note here that this is dict of site id to short name?\n",
    "# LW: IIUC I think you shouldn't need the site ids here explicitly, you should be able to extract them later. You do need the map of long site name to short site name. \n",
    "CA_SITE_META = {2:'Tahoma',\n",
    "             3:'Prep',\n",
    "             4:'Everest',\n",
    "             5:'Denali',\n",
    "             6:'Shasta',\n",
    "             7:'K2',\n",
    "             8:'Tamalpais'\n",
    "            }\n",
    "\n",
    "# AL: added this to replace the defaults you pass in earlier\n",
    "DEFAULT_SITE_IDS = list(CA_SITE_META.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: School Rosters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch CSV and put it into a DataFrame\n",
    "ELA_STATUSES_URL = 'https://drive.google.com/uc?export=download&id=1dK-050RcSingosBwLcuXBmrZavcfL8-j'\n",
    "\n",
    "# AL: so i know i said one thing about constants, but looking back, maybe the term i was looking for is \"configuration variable\", which this isn't. i'd keep `ELA_STATUSES_DATA` lowercase like a regular variable even though it's not supposed to be modified later\n",
    "ELA_STATUSES_DATA = pd.read_csv(ELA_STATUSES_URL)\n",
    "\n",
    "#Add site short names using the dictionary created above\n",
    "#LW: This could be omitted, since you cane use the map later to look these up.\n", 
    "ELA_STATUSES_DATA['SITE_SHORT_NAME'] = ELA_STATUSES_DATA['SITE_ID'].map(CA_SITE_META)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the data specified to be contained within the enrollment files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROSTER_DATA_COLUMNS = ['LOCAL_STUDENT_ID',\n",
    "                'STATE_STUDENT_ID',\n",
    "                'SITE_ID',\n",
    "                'SITE_NAME',\n",
    "                'FIRST_NAME',\n",
    "                'LAST_NAME',\n",
    "                'GRADE_LEVEL',\n",
    "                'CURRENT_SCHOOL_ENROLLMENT_START_DATE',\n",
    "                'CURRENT_SCHOOL_ENROLLMENT_END_DATE'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will be default run a roster report on all sites in CA using the given DataFrame.\n",
    "Individual or subsets of sites can be run by placing the site IDs in a list. Additionally a separate DataFrame can be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AL: i like this function. i can see a person reusing this in the future to maybe only create a roster on a subset of sites. replaced the list with `DEFAULT_SITE_IDS` here\n",
    
    "def create_rosters(site_ids = DEFAULT_SITE_IDS,\n",
    "                   ela_statuses_data = ELA_STATUSES_DATA\n",
    "                  ):\n",
    "    \n",
    "\n",
    "    # LW: Instead of iterating over site_ids, you could just iterate over (key,value) from a map of long name to short name.\n",
    "    for site_id in site_ids:\n",
    "        \n",
    "        # AL: it feels more concise to just pull this from `CA_SITE_META`, but maybe there's a reason for not doing that?\n",
    "\n",
    "        # LW: Iterating over the map of long name to short name inverts this to you looking up the site_id here.\n",
    "        #Get site's shortname to use in the filename\n",
    "        site_shortname = ela_statuses_data.loc[ela_statuses_data['SITE_ID'] == site_id,'SITE_SHORT_NAME'].values[0]\n",
    "\n",
    "\n",
    "        #filename as specified\n",
    "        filename = f'{site_shortname}_{site_id}_Roster_{TODAY}.csv'\n",
    "\n",
    "        # LW: +1 for disc sounding antiquated. 'Write files' is sufficient.\n",
    "        #Write files to disc and print\n",
    "        ela_statuses_data.loc[ela_statuses_data['SITE_ID'] == site_id,ROSTER_DATA_COLUMNS].to_csv(filename)\n",
    "            \n",
    "        print(f'Roster for {site_shortname} written to {filename}')\n",
    "    \n",
    "    print('All sites data written to disc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roster for Tahoma written to Tahoma_2_Roster_10-17-2020.csv\n",
      "Roster for Prep written to Prep_3_Roster_10-17-2020.csv\n",
      "Roster for Everest written to Everest_4_Roster_10-17-2020.csv\n",
      "Roster for Denali written to Denali_5_Roster_10-17-2020.csv\n",
      "Roster for Shasta written to Shasta_6_Roster_10-17-2020.csv\n",
      "Roster for K2 written to K2_7_Roster_10-17-2020.csv\n",
      "Roster for Tamalpais written to Tamalpais_8_Roster_10-17-2020.csv\n",
      "All sites data written to disc.\n"
     ]
    }
   ],
   "source": [
    "create_rosters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: English Proficiency Testing Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data URL\n",
    "MENTOR_DATA_URL = 'https://drive.google.com/uc?export=download&id=1wpKxw2rWB1a7jQBDunay0JfSO6lUiJ67'\n",
    "\n",
    "# Pull in and merge both sheets from the remote Excel document\n",
    "# This assumes the workbooks are consistent format with two sheets of data\n",
    "\n",
    "# AL: same thing mentioned above with lowercase naming. sorry for steering ya in the wrong direction\n",
    "MENTOR_DATA = pd.merge(pd.read_excel(MENTOR_DATA_URL, sheet_name = 0),\n",
    "                       pd.read_excel(MENTOR_DATA_URL, sheet_name = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Default ELA Statuses of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELA_STATUSES = ['EL','TBD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define columns for final output\n",
    "_Case and Spacing will be corrected before output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELA_PROF_DATA_COLUMNS = ['LOCAL_STUDENT_ID',\n",
    "                'STATE_STUDENT_ID',\n",
    "                'SITE_NAME',\n",
    "                'FIRST_NAME',\n",
    "                'LAST_NAME',\n",
    "                'GRADE_LEVEL',\n",
    "                'MENTOR_FIRST_NAME',\n",
    "                'MENTOR_LAST_NAME',\n",
    "                'CURRENT_ELA_STATUS',\n",
    "                'ELA_PRIMARY_LANGUAGE'\n",
    "               ]\n",
    "\n",
    "ELA_PROF_BLANK_COLUMNS = ['Notification Letter Sent Home',\n",
    "                 'Date Notification Letter Sent Home',\n",
    "                 'Date Listening Completed',\n",
    "                 'Date Reading Completed',\n",
    "                 'Date Writing Completed',\n",
    "                 'Date Speaking Completed',\n",
    "                 'Date Assessment Completed',\n",
    "                 'Assessment Deadline',\n",
    "                 'Notes'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will be default create a testing list in XLSX format with sheets for all sites in CA using the mentor DataFrame and ELA Status DF, filtering by ELA Statuses of \"ELA\" and \"TBD\".\n",
    "- Individual or subsets of sites can be run by placing the site IDs in a list.\n",
    "- Different ELA statuses could be defined as well via a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_lists(mentor_df = MENTOR_DATA,\n",
    "                      ela_statuses_df = ELA_STATUSES_DATA,\n",
    "                      # LW: Nit, no trailing underscore here probably?\n",
    "                      ela_statuses_ = ELA_STATUSES,\n",
    "                      site_ids = DEFAULT_SITE_IDS\n",
    "                     ):\n",
    "    \n",
    "   # Correct column names to save time later on a subsequent merge\n",
    "    mentor_df.columns = ['LOCAL_STUDENT_ID', 'MENTOR_GROUP_ID', 'MENTOR_ID', 'MENTOR_FIRST_NAME',\n",
    "           'MENTOR_LAST_NAME', 'MENTOR_FULL_NAME']\n",
    "    \n",
    "    # Merge ELA Status data with mentor data using 'LOCAL_STUDENT_ID'\n",
    "    test_list_data = pd.merge(ela_statuses_df,\n",
    "                           mentor_df,\n",
    "                           on = 'LOCAL_STUDENT_ID'\n",
    "                          )\n",
    "    \n",
    "    # Filter the data down to relevant columns needed\n",
    "    test_list_data = test_list_data.loc[test_list_data['CURRENT_ELA_STATUS'].isin(ela_statuses_),\n",
    "                                  ELA_PROF_DATA_COLUMNS]\n",
    "    \n",
    "    #Append empty columns\n",
    "    test_list_data[ELA_PROF_BLANK_COLUMNS] = ''\n",
    "\n",
    "    #Fix columns case from import to match requirements\n",
    "    fixed_columns = []\n",
    "    for column in test_list_data.columns:\n",
    "        fixed_columns.append(column.title().replace(\"_\",\" \").replace(\" Id\",\" ID\").replace('Ela ','ELA '))\n",
    "    test_list_data.columns = fixed_columns\n",
    "\n",
    "    \n",
    "    \n",
    "    test_list_filename = f'SPS_English_Proficiency_Testing_Lists_All_Schools_{TODAY}.xlsx'\n",
    "    \n",
    "    # AL: nit - i'd just say \"files written\" w/o the word \"disc\" because everyone's on the cloud these days, or sharepoint. feels a bit clunky\n",
    "\n",
    "    # Write file to disc\n",
    "    \n",
    "    with pd.ExcelWriter(path = test_list_filename, mode='w', engine = 'openpyxl') as writer:\n",
    "\n",
    "        print(f'Writing data to {test_list_filename}')\n",
    "\n",
    "        for site_id in site_ids:\n",
    "            site_shortname = ela_statuses_df.loc[ela_statuses_df['SITE_ID'] == site_id,'SITE_SHORT_NAME'].values[0]\n",
    "            site_name = ela_statuses_df.loc[ela_statuses_df['SITE_ID'] == site_id,'SITE_NAME'].values[0]\n",
    "            \n",
    "            \n",
    "            # Write data to disc\n",
    "            test_list_data.loc[test_list_data['Site Name'] == site_name].to_excel(writer,\n",
    "                                                                        sheet_name = site_shortname)\n",
    "            print(f'Data for {site_name} written.')\n",
    "            \n",
    "    print('All sites data written to disc.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data to SPS_English_Proficiency_Testing_Lists_All_Schools_10-17-2020.xlsx\n",
      "Data for Summit Public School: Tahoma written.\n",
      "Data for Summit Preparatory Charter High School written.\n",
      "Data for Everest Public High School written.\n",
      "Data for Summit Public School: Denali written.\n",
      "Data for Summit Public School: Shasta written.\n",
      "Data for Summit Public School: K2 written.\n",
      "Data for Summit Public School: Tamalpais written.\n",
      "All sites data written to disc.\n"
     ]
    }
   ],
   "source": [
    "create_test_lists()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
